<!doctype html><html lang=en><head><title>Differential Privacy | curiosities.dev</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo (https://gohugo.io/)"><meta name=description content="A data release mechanism is differentially private if any computation performed on the released data yields essentially the same result if a single data point is added/removed.
More specifically, let \(Q\) be any (probabilistic) query function. \(Q\) is \(\epsilon\)-differentially private if for all databases \(B\), \(B'\) that differ in one item, and for all functions \(F\), and all values \(y\):
$$ \mathbb{P}\{F(Q(B)) = y\} \le e^{\epsilon} \cdot \mathbb{P}\{F(Q(B')) = y\} $$..."><link rel=stylesheet type=text/css href=/css/main.min.css><link rel=preload href=/css/all_font_awesome_v5.9.min.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=/css/all_font_awesome_v5.9.min.min.css></noscript><link rel="shortcut icon" href=/img/favicon_io/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/img/favicon_io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon_io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon_io/favicon-16x16.png><script async type=text/javascript src=/js/OrganizeCitations.min.js></script><script async type=text/javascript src=/js/HighlightAnchor.min.js></script><script async type=text/javascript src=/js/SummaryPageUtils.min.js></script></head><svg id="background-svg"/><body><div class=container id=main_div><form action=/search method=get id=globalSearchForm><input type=text id=q name=q title="Search Query">
<input type=submit id=submitButton value=Search></form><nav aria-label=Breadcrumb class=breadcrumb><ul><li><a href=https://www.curiosities.dev/>Home</a></li><li><a href=https://www.curiosities.dev/politics-and-governance/>Politics and Governance</a></li><li><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/>Information and Technology Policy [WWS 351]</a></li><li><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/07-privacy/>07. Privacy</a></li><li class=active><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/07-privacy/differential-privacy/>Differential Privacy</a></li></ul></nav><main><article><header><h1>Differential Privacy</h1><p class=meta>Dated Jan 22, 2019;
last modified on Sun, 14 Mar 2021</p></header><p>A data release mechanism is differentially private if any computation performed on the released data yields essentially the same result if a single data point is added/removed.</p><p>More specifically, let \(Q\) be any (probabilistic) query function. \(Q\) is \(\epsilon\)-differentially private if for all databases \(B\), \(B'\) that differ in one item, and for all functions \(F\), and all values \(y\):</p><p>$$ \mathbb{P}\{F(Q(B)) = y\} \le e^{\epsilon} \cdot \mathbb{P}\{F(Q(B')) = y\} $$</p><p>\(\epsilon\) is a privacy parameter. Increasing \(\epsilon\) improves accuracy, but reduces privacy.</p><div class=comment-holder><div class=comment><p>Cynthia Dwork, the pioneer of Differential Privacy,
<a href=http://www.sigact.org/prizes/knuth/citation2020.pdf target=_blank rel=noopener>has just won the 2020 Knuth Prize
<i class="fas fa-fw fa-external-link-alt" aria-hidden=true></i></a>.</p></div></div><div class=comment-holder><div class=comment><p>See
<a href=https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id/dp-blog target=_blank rel=noopener>Differential Privacy Blog Series |
NIST
<i class="fas fa-fw fa-external-link-alt" aria-hidden=true></i></a>for more discussions on Differential Privacy.</p></div></div></article><table border=0><tr class=no-decoration id=randomSelectorContainer><td class=no-decoration></td><td class=no-decoration></td><td class=no-decoration><span class=link-style onclick=goToRandomPage();>Random Link ¯\_(ツ)_/¯</span></td></tr><tr class=no-decoration><td class=no-decoration>Mar 25, 2019</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/07-privacy/differential-privacy/01-big-data-and-privacy/>Motivation for Differential Privacy in Datasets</a>
<span class=meta>2 min; updated Mar 14, 2021
<button id=172d175b2924d928fae432eb40dabfdb-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=172d175b2924d928fae432eb40dabfdb-summary style=display:none>The goal is to make large datasets safe, i.e. no harm to you from having your data included.
Sanitize and Transfer Model Remove all PII, _e.g. name, SSN, mobile number, etc, before releasing the dataset.
However, the list of PII is not necessarily complete. Furthermore, combinations of seemingly non-PII data can be jointly identifying.
Using an auxilliary dataset is a common re-identification method, e.g. Narayanan and Shmatikov [2010] combined IMDB ratings and comments to deanonymize a Netflix dataset....</p></td></tr><tr class=no-decoration><td class=no-decoration>Jun 1, 2010</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/07-privacy/differential-privacy/2010-narayanan-myths-and-fallacies-of-pii/>Myths and Fallacies of 'Personally Identifiable Information'</a>
<span class=meta>3 min; updated Sep 5, 2022
<button id=9977b66f34f44a281ccbe8d8a6f12b39-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=9977b66f34f44a281ccbe8d8a6f12b39-summary style=display:none>Myths and Fallacies of 'Personally Identifiable Information'. Narayanan, Arvind; Shmatikov, Vitaly. dl.acm.org . Jun 1, 2010. What is PII? From Breach Notification Laws: For example, California Senate Bill 1386: SSNs, driver’s license numbers, financial accounts.
The list can never be exhaustive, e.g. email addresses and telephone numbers are not mentioned in Bill 1386.
Focuses on data that are commonly used for authenticating an individual. Ignores data that reveals some sensitive information about an individual...</p></td></tr><tr class=no-decoration><td class=no-decoration>May 7, 2017</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/politics-and-governance/wws351-it-policy/07-privacy/differential-privacy/2017-05-07-dp-primer-nontechnical/>Differential Privacy: A Primer for a Non-technical Audience</a>
<span class=meta>4 min; updated Sep 5, 2022
<button id=7f916d86d28da4f76c8d17fe056581c3-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=7f916d86d28da4f76c8d17fe056581c3-summary style=display:none>Differential Privacy: A Primer for a Non-technical Audience. Kobbi Nissim; Thomas Steinke; Alexandra Wood; Micah Altman; Aaron Bembenek; Mark Bun; Marco Gaboardi; David R. O'Brien; Salil Vadhan. www.ftc.gov . May 7, 2017. What Does DP Guarantee? It is a question of whether a particular computation (not output) preserves privacy.
DP only guarantees that no information specific to an individual is revealed by the computation. DP doesn&rsquo;t protect against information that could be learned even with an individual opting out of a dataset, e....</p></td></tr></table><script>let pageURLs=[];const alternateOrganizations=new Set(["tags","categories","domains","authors","publications"]);fetch("/json/site_tree.json").then(response=>response.json()).then(siteTree=>{const currentPath=document.location.pathname;let node=siteTree;currentPath.split("/").forEach((subpath)=>{if(!subpath)return;node=node[subpath];});if(!node)return;function populateRelevantURLs(partialURL,currentNode){const currentNodeKeys=Object.keys(currentNode);currentNodeKeys.forEach((key)=>{if(key==="_meta")return;if(currentPath==="/"&&alternateOrganizations.has(key))
return;let nextPartialURL=partialURL===""?key:`${partialURL}/${key}`;populateRelevantURLs(nextPartialURL,currentNode[key]);});if(currentNodeKeys.length===0&&partialURL){pageURLs.push(partialURL);}}
populateRelevantURLs("",node);}).then(()=>{if(pageURLs.length===0){document.getElementById("randomSelectorContainer").style.display="none";}});function goToRandomPage(){let idx=Math.floor(Math.random()*(pageURLs.length));window.open(pageURLs[idx],"_self");}</script></main></div><footer><a href=mailto:d.chege711@gmail.com>Email</a>
<a href=/about>About</a>
<a href=/search>Search</a></footer></body></html>