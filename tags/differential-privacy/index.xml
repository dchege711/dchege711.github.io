<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>differential-privacy on Chege's Blog</title><link>https://www.curiosities.dev/tags/differential-privacy/</link><description>Recent content in differential-privacy on Chege's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 22 Jan 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/tags/differential-privacy/index.xml" rel="self" type="application/rss+xml"/><item><title>Differential Privacy</title><link>https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/privacy-enhancing-tech/differential-privacy/</link><pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/privacy-enhancing-tech/differential-privacy/</guid><description>A data release mechanism is differentially private if any computation performed on the released data yields essentially the same result if a single data point is added/removed.
More specifically, let \(Q\) be any (probabilistic) query function. \(Q\) is \(\epsilon\)-differentially private if for all databases \(B\), \(B'\) that differ in one item, and for all functions \(F\), and all values \(y\):
$$ \mathbb{P}\{F(Q(B)) = y\} \le e^{\epsilon} \cdot \mathbb{P}\{F(Q(B')) = y\} $$</description></item></channel></rss>