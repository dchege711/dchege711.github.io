<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>developers.google.com on Chege's Blog</title><link>https://www.curiosities.dev/domains/developers.google.com/</link><description>Recent content in developers.google.com on Chege's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/domains/developers.google.com/index.xml" rel="self" type="application/rss+xml"/><item><title>03. The Surgical Team</title><link>https://www.curiosities.dev/computer-science/swe-in-practice/mythical-man-month/brooks-03-the-surgical-team/</link><pubDate>Tue, 01 Oct 1974 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/computer-science/swe-in-practice/mythical-man-month/brooks-03-the-surgical-team/</guid><description>The Dilemma There are wide productivity variations between good programmers and poor ones. Sackman et. al. found 10:1 ratios. The data showed no correlation between experience and performance.
The idea of a 10x developer is mostly ridiculed in my online circles. That said, some jobs have X years of experience as a requirement. How can we resolve these contradictions?
The major part of the cost of large teams is communication, and system debugging to correct the ill effects of miscommunication.</description></item><item><title>ML Crash Course [dev@google]</title><link>https://www.curiosities.dev/computer-science/machine-learning/ml-crash-course/</link><pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/computer-science/machine-learning/ml-crash-course/</guid><description> Machine Learning Crash Course. Google. developers.google.com . Feb 28, 2018.</description></item><item><title>[ToDo] Machine Learning Crash Course</title><link>https://www.curiosities.dev/todo/ai-and-machine-learning/machine-learning-crash-course/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/todo/ai-and-machine-learning/machine-learning-crash-course/</guid><description>ML Concepts
Introduction to ML Framing Descending into ML Reducing Loss First Steps with TF Generalization Training and Test Sets Validation Set Representation Feature Crosses Regularization: Simplicity Logistic Regression Classification Regularization: Sparsity Neural Networks Training Neural Nets Multi-Class Neural Nets Embeddings ML Engineering
Production ML Systems Static vs. Dynamic Training Static vs. Dynamic Inference Data Dependencies Fairness ML Systems in the Real World
Cancer Prediction Literature Guidelines Machine Learning Crash Course.</description></item></channel></rss>