<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>nicholas.carlini.com on Chege's Blog</title><link>https://www.curiosities.dev/domains/nicholas.carlini.com/</link><description>Recent content in nicholas.carlini.com on Chege's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 24 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/domains/nicholas.carlini.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Using LLMs to Enhance My Capabilities</title><link>https://www.curiosities.dev/computer-science/large-language-models/using-llms/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/computer-science/large-language-models/using-llms/</guid><description>Sample Use Cases LLMs are increasingly here to stay despite the reservations . How can I use them to enhance my capabilities?
Look out for the Gell-Man amnesia effect. You prompt the LLM on some subject you know well. You read the response and see the LLM has absolutely no understanding of either the facts or the issues. In any case, you read with exasperation or amusement the multiple errors in the response, and then ask it about something else, and read the response as if it&amp;rsquo;s more accurate than the baloney you just read.</description></item></channel></rss>