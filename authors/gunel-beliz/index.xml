<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gunel, Beliz on Chege&#39;s Blog</title>
    <link>https://www.curiosities.dev/authors/Gunel-Beliz/</link>
    <description>Recent content in Gunel, Beliz on Chege&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/authors/Gunel-Beliz/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Similarity Measures</title>
      <link>https://www.curiosities.dev/computer-science/machine-learning/ele364-machine-learning-and-predictive-analytics/05-similarity-based-learning/01-similarity-measures/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/computer-science/machine-learning/ele364-machine-learning-and-predictive-analytics/05-similarity-based-learning/01-similarity-measures/</guid>
      <description>To classify something, find things that are similar and label it with the same class as the most similar thing.
The feature space is \(N-d\), where \(N\) is the number of features. Each instance is mapped to a point. The descriptive features become the axes.
The Similarity Metric Mathematically, it must conform to these 4 criteria:
 Non-negativity: \(f(a, b) \ge 0\) Identity of Indiscernables: \( f(a, b) = 0 \iff a = b \) Symmetry: \( f(a, b) = f(b, a) \) Subaddivity (Triangular inequality): \( f(a, b) \le f(a, c) + f(c, b) \)  Why are non-negativity and triangular inequality important?</description>
    </item>
    
    <item>
      <title>Similarity Measures</title>
      <link>https://www.curiosities.dev/computer-science/machine-learning/similarity-based-learning/similarity-measures/</link>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/computer-science/machine-learning/similarity-based-learning/similarity-measures/</guid>
      <description>To classify something, find things that are similar and label it with the same class as the most similar thing.
The feature space is \(N-d\), where \(N\) is the number of features. Each instance is mapped to a point. The descriptive features become the axes.
The Similarity Metric Mathematically, it must conform to these 4 criteria:
 Non-negative: \(f(a, b) \ge 0\) Identity: \( f(a, b) = 0 \iff a = b \) Symmetry: \( f(a, b) = f(b, a) \) Triangular inequality: \( f(a, b) \le f(a, c) + f(c, b) \)  Why are non-negativity and triangular inequality important?</description>
    </item>
    
    <item>
      <title>Online Markets</title>
      <link>https://www.curiosities.dev/business/2021-10-04-online-markets/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/business/2021-10-04-online-markets/</guid>
      <description>WWW &amp;lsquo;21: The Web Conference 2021 REST: Relational Event-Driven Stock Trend Forecasting REST, an event-driven stock trend forecasting framework, that overcomes two limitations of existing event-driven models. Models the stock context, and learns the effect of event information on the stocks under different contexts. Constructs a stock graph and designs a new propagation layer to propagate the effect of event information from related stocks. 
The value of stock trend forecasting is not unanimous, e.</description>
    </item>
    
  </channel>
</rss>
