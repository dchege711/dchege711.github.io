<!doctype html><html lang=en><head><title>CS 329A: Self-Improving AI Agents | curiosities.dev</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo (https://gohugo.io/)"><meta name=description content="Stanford CS329A | Self-Improving AI Agents.  Azalia Mirhoseini; Aakanksha Chowdhery; Mert Yuksekgonul; Jon Saad-Falcon. cs329a.stanford.edu  .  Accessed Jul 11, 2025.   Test-time Compute Scaling  Large Language Monkeys: Scaling Inference Compute with Repeated Sampling Archon; An Architecture Search Framework for Inference-Time Techniques Scaling LLM Test-Time Compute Optimally Can Be More Effective Than Scaling Model Parameters   Self-Improvement Techniques with Verifiers:  Training Verifiers to Solve Math Word Problems Let&rsquo;s Verify Step by Step Math-Shepherd: Verify and Reinforce LLMs Step-by-step Without Human Annotations   Self-Improvement Techniques with RL  Constitutional AI: Harmlessness from AI Feedback STaR: Bootstrapping Reasoning With Reasoning Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models   Self-Improvement Techniques with Search  Thinking Fast and Slow with Deep Learning and Tree Search Competitive-level Code Generation with AlphaCode AlphaCode 2 Technical Report   Open-ended Agent Learning in the Era of Foundation Models  The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery Automated Design of Agentic Systems   Augmenting LLMs with Tool Use/Actions  ReAct: Synergizing Reasoning and Acting in Language Models Toolformer: Language Models Can Teach Themselves to Use Tools RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning   Planning and Multi-Step Reasoning  Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models LLMs Still Can&rsquo;t Plan; Can LRMs?..."><meta property="og:title" content="CS 329A: Self-Improving AI Agents"><meta property="og:description" content="Stanford CS329A | Self-Improving AI Agents.  Azalia Mirhoseini; Aakanksha Chowdhery; Mert Yuksekgonul; Jon Saad-Falcon. cs329a.stanford.edu  .  Accessed Jul 11, 2025.   Test-time Compute Scaling  Large Language Monkeys: Scaling Inference Compute with Repeated Sampling Archon; An Architecture Search Framework for Inference-Time Techniques Scaling LLM Test-Time Compute Optimally Can Be More Effective Than Scaling Model Parameters   Self-Improvement Techniques with Verifiers:  Training Verifiers to Solve Math Word Problems Let&rsquo;s Verify Step by Step Math-Shepherd: Verify and Reinforce LLMs Step-by-step Without Human Annotations   Self-Improvement Techniques with RL  Constitutional AI: Harmlessness from AI Feedback STaR: Bootstrapping Reasoning With Reasoning Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models   Self-Improvement Techniques with Search  Thinking Fast and Slow with Deep Learning and Tree Search Competitive-level Code Generation with AlphaCode AlphaCode 2 Technical Report   Open-ended Agent Learning in the Era of Foundation Models  The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery Automated Design of Agentic Systems   Augmenting LLMs with Tool Use/Actions  ReAct: Synergizing Reasoning and Acting in Language Models Toolformer: Language Models Can Teach Themselves to Use Tools RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning   Planning and Multi-Step Reasoning  Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models LLMs Still Can&rsquo;t Plan; Can LRMs?..."><meta property="og:type" content="website"><meta property="og:url" content="https://www.curiosities.dev/todo/ai-and-machine-learning/cs329a-self-improving-ai-agents/"><meta property="og:site_name" content="curiosities.dev"><link rel=stylesheet type=text/css href=/css/main.min.css><link rel=preload href=/css/all_font_awesome_v5.9.min.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=/css/all_font_awesome_v5.9.min.min.css></noscript><link rel="shortcut icon" href=/img/favicon_io/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/img/favicon_io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon_io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon_io/favicon-16x16.png><script async type=text/javascript src=/js/OrganizeCitations.min.js></script><script async type=text/javascript src=/js/HighlightAnchor.min.js></script><script async type=text/javascript src=/js/SummaryPageUtils.min.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body><div class=container id=main_div><form action=/search method=get id=globalSearchForm><input type=text id=q name=q title="Search Query">
<input type=submit id=submitButton value=Search></form><nav aria-label=Breadcrumb class=breadcrumb><ul><li><a href=https://www.curiosities.dev/>Home</a></li><li><a href=https://www.curiosities.dev/todo/>To-Do List</a></li><li><a href=https://www.curiosities.dev/todo/ai-and-machine-learning/>[ToDo] AI and Machine Learning</a></li><li class=active><a href=https://www.curiosities.dev/todo/ai-and-machine-learning/cs329a-self-improving-ai-agents/>CS 329A: Self-Improving AI Agents</a></li></ul></nav><section><header><h1>CS 329A: Self-Improving AI Agents</h1><p class=meta>Dated Jul 11, 2025;
last modified on Fri, 11 Jul 2025</p></header><div id=toc-then-article><aside id=toc><nav id=TableOfContents></nav></aside><article id=main-article><div class=citation citation-icon-class="fas fa-fw fa-globe" cited-by-count is-main><cite id=CS329A>Stanford CS329A | Self-Improving AI Agents<i>.</i></cite>
Azalia Mirhoseini; Aakanksha Chowdhery; Mert Yuksekgonul; Jon Saad-Falcon.
<a href=https://cs329a.stanford.edu/ target=_blank rel=noopener><img src="https://www.google.com/s2/favicons?domain=cs329a.stanford.edu" loading=lazy aria-hidden=true width=16 height=16>
<i>cs329a.stanford.edu</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden=true></i></a>.
<i class="fas fa-fw fa-globe" aria-hidden=true></i>Accessed Jul 11, 2025.</div><ul><li>Test-time Compute Scaling<ul><li>Large Language Monkeys: Scaling Inference Compute with Repeated Sampling</li><li>Archon; An Architecture Search Framework for Inference-Time Techniques</li><li>Scaling LLM Test-Time Compute Optimally Can Be More Effective Than Scaling
Model Parameters</li></ul></li><li>Self-Improvement Techniques with Verifiers:<ul><li>Training Verifiers to Solve Math Word Problems</li><li>Let&rsquo;s Verify Step by Step</li><li>Math-Shepherd: Verify and Reinforce LLMs Step-by-step Without Human
Annotations</li></ul></li><li>Self-Improvement Techniques with RL<ul><li>Constitutional AI: Harmlessness from AI Feedback</li><li>STaR: Bootstrapping Reasoning With Reasoning</li><li>Beyond Human Data: Scaling Self-Training for Problem-Solving with Language
Models</li></ul></li><li>Self-Improvement Techniques with Search<ul><li>Thinking Fast and Slow with Deep Learning and Tree Search</li><li>Competitive-level Code Generation with AlphaCode</li><li>AlphaCode 2 Technical Report</li></ul></li><li>Open-ended Agent Learning in the Era of Foundation Models<ul><li>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</li><li>Automated Design of Agentic Systems</li></ul></li><li>Augmenting LLMs with Tool Use/Actions<ul><li>ReAct: Synergizing Reasoning and Acting in Language Models</li><li>Toolformer: Language Models Can Teach Themselves to Use Tools</li><li>RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning</li></ul></li><li>Planning and Multi-Step Reasoning<ul><li>Language Agent Tree Search Unifies Reasoning, Acting, and Planning in
Language Models</li><li>LLMs Still Can&rsquo;t Plan; Can LRMs? A Preliminary Evaluation of OpenAI&rsquo;s o1 on
PlanBench</li><li>ADaPT: As-Needed Decomposition and Planning with Language Models</li></ul></li><li>Reasoning Across Modalities<ul><li>Navigating the Digital World as Humans Do: Universal Visual Grounding for
GUI Agents</li><li>Developing a Computer Use Model</li><li>The Dawn of GUI Agent: A Preliminary Study with Claude 3.5 Computer Use</li></ul></li><li>Benchmarks and Challenges in Evaluating Agents<ul><li>SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</li><li>KernelBench: Can LLMs Write GPU Kernels?</li><li>RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Models Against
Human Experts</li><li>MLE-Bench: Evaluating Machine Learning Agents on Machine Learning
Engineering</li><li>\(\tao\)-bench: A Benchmark for Tool-Agent-User Interaction in Real-World
Domains</li><li>GAIA: A Benchmark for General AI Assistants</li></ul></li><li>AI Coding Agents<ul><li>SWE-Agent: Agent-Computer Interfaces Enable Automated Software Engineering</li><li>SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and
Iterative Refinement</li><li>SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?</li></ul></li><li>Agent Orchestration Frameworks<ul><li>AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</li></ul></li><li>Augmenting LLMs with Retrieval/Memory<ul><li>Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?</li><li>Contextual Retrieval</li><li>MemGPT: Towards LLMs as Operating Systems</li></ul></li><li>Multimodal AI Agents</li><li>Multi-agent Systems and Future Research Areas<ul><li>Multi-agent Fine-tuning: Self Improvement with Diverse Reasoning Chains</li><li>Mixture-of-Agents Enhances Large Language Model Capabilities</li><li>CodeMonkeys: Scaling Test-Time Compute for Software Engineering</li></ul></li></ul></article><div style=font-size:smaller><aside id=authors-holder style="margin:0 0 2%">Cited Authors:
<a href=/cited-authors/Chowdhery-Aakanksha>Chowdhery, Aakanksha</a>
<a href=/cited-authors/Mirhoseini-Azalia>Mirhoseini, Azalia</a>
<a href=/cited-authors/Saad-Falcon-Jon>Saad-Falcon, Jon</a>
<a href=/cited-authors/Yuksekgonul-Mert>Yuksekgonul, Mert</a></aside><aside id=domains-holder style="margin:0 0 2%">Cited Domains:
<a href=/domains/cs329a.stanford.edu style="margin:0 2px"><img src="https://www.google.com/s2/favicons?domain=cs329a.stanford.edu" loading=lazy aria-hidden=true width=16 height=16>
cs329a.stanford.edu</a></aside></div></div><footer><a href=https://www.curiosities.dev/todo/ai-and-machine-learning/ai-a-modern-approach/>&#171; [ToDo] AI: A Modern Approach</a>
<a href=https://www.curiosities.dev/todo/ai-and-machine-learning/cs324-large-language-models/>[ToDo] CS 324: Large Language Models &#187;</a></footer></section></div><footer><a href=/about>About</a>
<a href=/search>Search</a></footer></body></html>