<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Wodecki, Ben on Chege's Blog</title><link>https://www.curiosities.dev/cited-authors/Wodecki-Ben/</link><description>Recent content in Wodecki, Ben on Chege's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 03 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/cited-authors/Wodecki-Ben/index.xml" rel="self" type="application/rss+xml"/><item><title>LLMs: Stochastic Parrots ðŸ¦œ and How (Not) to Use Them</title><link>https://www.curiosities.dev/computer-science/large-language-models/stochastic-parrots/</link><pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.curiosities.dev/computer-science/large-language-models/stochastic-parrots/</guid><description>was written in a period when NLP practitioners are producing bigger (# of parameters; size of training data) language models (LMs), and pushing the top scores on benchmarks. The paper itself was controversial because it led to Gebru being fired from Google, following disagreements with her managers on conditions (withdraw, or remove Google-affiliated authors) for publishing the paper.
A lot changed since mid-2021, when I initially wrote this page.</description></item></channel></rss>