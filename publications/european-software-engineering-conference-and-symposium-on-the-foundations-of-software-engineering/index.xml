<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>European Software Engineering Conference and Symposium on the Foundations of Software Engineering on Chege&#39;s Blog</title>
    <link>https://www.curiosities.dev/publications/european-software-engineering-conference-and-symposium-on-the-foundations-of-software-engineering/</link>
    <description>Recent content in European Software Engineering Conference and Symposium on the Foundations of Software Engineering on Chege&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.curiosities.dev/publications/european-software-engineering-conference-and-symposium-on-the-foundations-of-software-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Software Engineering Journal Reviews</title>
      <link>https://www.curiosities.dev/computer-science/2022-01-16-swe-journal-reviews/</link>
      <pubDate>Sat, 15 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/computer-science/2022-01-16-swe-journal-reviews/</guid>
      <description>Formal Software Design Alloy is an open-source language and analyzer for software modeling. An Alloy model is a collection of constraints that describe a set of structures, e.g. all possible security configurations of a web application. Alloy&amp;rsquo;s tool, the Alloy Analyzer is a solver that takes the constraints of a model and finds structures that satisfy them. 
The Alloy Analyzer leverages a SAT solver, and this precludes Alloy from analyzing optimization problems.</description>
    </item>
    
    <item>
      <title>Journal Reviews on Fairness</title>
      <link>https://www.curiosities.dev/computer-science/bias-and-fairness/2021-10-04-journal-reviews-on-fairness/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/computer-science/bias-and-fairness/2021-10-04-journal-reviews-on-fairness/</guid>
      <description>Meta Instead of changing the data or learners in multiple ways and then see if fairness improves,  postulate that the root causes of bias are the prior decisions that generated the training data. These affect (a) what data was selected, and (b) the labels assigned to the examples. They propose the \(\text{Fair-SMOTE}\) (Fair Synthetic Minority Over Sampling Technique) algorithm which (1) removes biased labels (via situation testing: if the model&amp;rsquo;s prediction for a data point changes once all of the data points&#39; protected attributes  are flipped, then that label is biased and the data point is discarded), and (2) rebalances internal distributions such that based on a protected attribute, examples are equal in both positive and negative classes.</description>
    </item>
    
    <item>
      <title>Software Vulnerabilities Introduced by Dependencies</title>
      <link>https://www.curiosities.dev/computer-science/2020-11-14-software-dependencies/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.curiosities.dev/computer-science/2020-11-14-software-dependencies/</guid>
      <description>Bloated Dependencies A bloated dependency is one which is packaged in the application binary, but is not needed to run the application.
There are two levels to this: (1) a source file declares a dependency on foo but never actually uses foo, and (2) the application as a whole never uses foo. An optimal de-bloating solution would first address (1) and then tackle (2).
Some languages may have better tooling than others when it comes to automatically de-bloating their dependencies.</description>
    </item>
    
  </channel>
</rss>
