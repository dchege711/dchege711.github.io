<!doctype html><html lang=en><head><title>Introduction to LLMs | curiosities.dev</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo (https://gohugo.io/)"><meta name=description content="What is a Language Model? A language model (LM) is a probability distribution over sequences of tokens. Suppose we have a vocabulary \(\mathcal{V}\) of a set of tokens, then a language model \(p\) assigns each sequence of tokens \(x_1, &mldr;, x_L \in \mathcal{V} \) a probability. 
To assign meaningful probabilities to all sequences requires syntactic knowledge and world knowledge. Given \( \mathcal{V} = \{ \text{ate}, \text{ball}, \text{cheese}, \text{mouse}, \text{the} \} \):..."><meta property="og:title" content="Introduction to LLMs"><meta property="og:description" content="What is a Language Model? A language model (LM) is a probability distribution over sequences of tokens. Suppose we have a vocabulary \(\mathcal{V}\) of a set of tokens, then a language model \(p\) assigns each sequence of tokens \(x_1, &mldr;, x_L \in \mathcal{V} \) a probability. 
To assign meaningful probabilities to all sequences requires syntactic knowledge and world knowledge. Given \( \mathcal{V} = \{ \text{ate}, \text{ball}, \text{cheese}, \text{mouse}, \text{the} \} \):..."><meta property="og:type" content="website"><meta property="og:url" content="https://www.curiosities.dev/computer-science/large-language-models/intro-to-llms/"><meta property="og:site_name" content="curiosities.dev"><link rel=stylesheet type=text/css href=/css/main.min.css><link rel=preload href=/css/all_font_awesome_v5.9.min.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=/css/all_font_awesome_v5.9.min.min.css></noscript><link rel="shortcut icon" href=/img/favicon_io/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/img/favicon_io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon_io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon_io/favicon-16x16.png><script async type=text/javascript src=/js/OrganizeCitations.min.js></script><script async type=text/javascript src=/js/HighlightAnchor.min.js></script><script async type=text/javascript src=/js/SummaryPageUtils.min.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script></head><body><div class=container id=main_div><form action=/search method=get id=globalSearchForm><input type=text id=q name=q title="Search Query">
<input type=submit id=submitButton value=Search></form><nav aria-label=Breadcrumb class=breadcrumb><ul><li><a href=https://www.curiosities.dev/>Home</a></li><li><a href=https://www.curiosities.dev/computer-science/>Computer Science & Software Engineering</a></li><li><a href=https://www.curiosities.dev/computer-science/large-language-models/>Large Language Models</a></li><li class=active><a href=https://www.curiosities.dev/computer-science/large-language-models/intro-to-llms/>Introduction to LLMs</a></li></ul></nav><section><header><h1>Introduction to LLMs</h1><p class=meta>Dated Dec 14, 2023;
last modified on Sun, 17 Dec 2023</p></header><div id=toc-then-article><aside id=toc><nav id=TableOfContents><ul><li><a href=#what-is-a-language-model>What is a Language Model?</a></li><li><a href=#a-brief-history>A Brief History</a></li><li><a href=#references>References</a></li></ul></nav></aside><article id=main-article><h2 id=what-is-a-language-model>What is a Language Model?</h2><p>A language model (LM) is a probability distribution over sequences of tokens.
Suppose we have a vocabulary \(\mathcal{V}\) of a set of tokens, then a
language model \(p\) assigns each sequence of tokens \(x_1, &mldr;, x_L \in
\mathcal{V} \) a probability. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>To assign meaningful probabilities to all sequences requires <strong>syntactic
knowledge and world knowledge.</strong> Given \( \mathcal{V} = \{ \text{ate},
\text{ball}, \text{cheese}, \text{mouse}, \text{the} \} \):</p><ul><li>The LM should assign a low value to \(p(\text{mouse}, \text{the}, \text{the},
\text{cheese}, \text{ate})\) because it&rsquo;s ungrammatical (syntactic
knowledge).</li><li>The LM should assign \( p(\text{the}, \text{mouse}, \text{ate}, \text{the},
\text{cheese}) \gt p(\text{the}, \text{cheese}, \text{ate}, \text{the},
\text{mouse}) \) because of world knowledge.</li></ul><p><span class=citation-ref><a href=#CS324Intro></a></span></p><p>We can also generate a sequence given an LM. The purest way to do this is to
sample a sequence \(x_{1:L}\) with probability equal to \(p(x_{1:L})\). In
practice, we don&rsquo;t sample directly from an LM because of limitations of real LMs
and the desire to get something closer to the &ldquo;best&rdquo; sequence and not just an
&ldquo;average&rdquo; sequence. <span class=citation-ref><a href=#CS324Intro></a></span></p><div class=comment-holder><div class="comment open-comment"><p>What are the said limitations of real-life LMs that prevent direct sampling?</p></div></div><p>Using the chain rule of probability:</p><p>$$ p(x_{1:L}) = p(x_1) p(x_2 | x_1) p(x_3 | x1, x_2) &mldr; p(x_L | x_{1:L-1}) =
\Pi_{i=1}^{L} p(x_i | x_{1:i-1}) $$</p><p>&mldr; for example:</p><p>$$ p(\text{GSW}, \text{beats}, \text{Cavs}) = p(\text{GSW}) \cdot p(\text{beats}
| \text{GSW}) \cdot p(\text{Cavs} | \text{GSW}, \text{beats}) $$</p><p><span class=citation-ref><a href=#CS324Intro></a></span></p><p>An autoregressive language model is one where each conditional distribution
\(p(x_i | x_{1:i-1})\) can be computed efficiently. To generate a sequence
\(x_{1:L}\) from an autoregressive LM \(p\), we sample one token at a time,
i.e., for \(i = 1, &mldr;, L\):</p><p>$$ x_i \sim p \left(x_i | x_{1:i-1} \right)^{1/T} $$</p><p>&mldr; where \(T \ge 0\) is a temperature that controls randomness:</p><ul><li>\(T = 0\): deterministically choose the most probable \(x_i\).</li><li>\(T = 1\): sample &ldquo;normally&rdquo; from the pure LM.</li><li>\(T = \infty \): sample from a uniform distribution over \(\mathcal{V}\).</li></ul><p><span class=citation-ref><a href=#CS324Intro></a></span></p><p>Raising the probabilities to power \(1/T\) may make them not sum to \(1\),
but this is fixed by re-normalizing the distribution:</p><p>$$ p_T(x_i | x_{1:i-1}) \propto p \left( x_i | x_{1:i-1} \right) ^{1/T} $$</p><p>&mldr; also called the annealed conditional probability distribution. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>We can perform conditional generation by specifying some prefix sequence (called
a prompt) and sampling the rest (called the completion). Conditional generation
allows LMs to solve a variety of tasks by simply changing the prompt. <span class=citation-ref><a href=#CS324Intro></a></span></p><h2 id=a-brief-history>A Brief History</h2><p>In 1948, Claude Shannon introduced the entropy of a distribution as:</p><p>$$ H(p) = \sum_{x} p(x) log \frac{1}{p(x)} $$</p><p>&mldr; to measure the expected number of bits any algorithm needs to encode a
sample \(x \sim p \) into a bit-string. Intuitively, \(log \frac{1}{p(x)}\)
is the length of code used to represent an element \(x\) that occurs with
probability \(p(x)\). <span class=citation-ref><a href=#CS324Intro></a></span></p><p>Shannon also described cross entropy:</p><p>$$ H(p, q) = \sum_{x} p(x) log \frac{1}{q(x)} $$</p><p>&mldr; where the compression scheme is given by the model \(q\). <span class=citation-ref><a href=#CS324Intro></a></span></p><p>Crucially, \(H(p, q) \ge H(p)\), and so we can get better estimates of
\(H(p)\) by constructing better models \(q\), as measured by \(H(p, q)\).
\(H(p)\) is generally inaccessible if \(p\) is English. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>In an n-gram model the prediction of a token \(x_i\) only depends on the last
\(n-1\) characters rather than the full history:</p><p>$$ p(x_i | x_{1:i-1}) = p(x_i | x_{i-(n-1):i-1}) $$</p><p><span class=citation-ref><a href=#CS324Intro></a></span></p><p>While fitting n-gram models to data is extremely computationally cheap and
scalable:</p><ul><li>If \(n\) is too small, then the model can&rsquo;t capture long-range dependencies.</li><li>If \(n\) is too big, then it&rsquo;s statistically infeasible to get good
estimates as almost all reasonable long sequences show up 0 times even in
large corpora.</li></ul><p>As a result, LMs were limited to tasks like speech recognition and machine
translation where only capturing local dependencies wasn&rsquo;t a huge problem. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>Bengio et al., 2003 pioneered LMs where \(p(x_i | x_{i-(n-1): i-1})\) is given
by a neural network, making it statistically feasible to estimate neural LMs for
much larger values of \(n\). However, the main challenge was that training
neural networks was much more computationally expensive. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>Recurrent Neural Networks (RNNs), including Long Short Term Memory (LSTMs),
effectively made \(n = \infty \), but these were hard to train. <span class=citation-ref><a href=#CS324Intro></a></span></p><p>Transformers returned to having fixed content length \(n\), but were much
easier to train and exploited the parallelism of GPUs. Also, \(n\) could be
made &ldquo;large enough&rdquo; for many applications (GPT-3 used \(n = 2048\)). <span class=citation-ref><a href=#CS324Intro></a></span></p><h2 id=references>References</h2><ol><li><div class=citation citation-icon-class="fas fa-fw fa-globe" cited-by-count is-main><cite id=CS324Intro>Introduction | CS324<i>.</i></cite>
Percy Liang; Tatsunori Hashimoto; Christopher Ré.
<a href=https://stanford-cs324.github.io/winter2022/lectures/introduction/ target=_blank rel=noopener><img src="https://www.google.com/s2/favicons?domain=stanford-cs324.github.io" loading=lazy aria-hidden=true width=16 height=16>
<i>stanford-cs324.github.io</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden=true></i></a>.
2022.
<i class="fas fa-fw fa-globe" aria-hidden=true></i>Accessed Dec 14, 2023.</div></li></ol></article><div style=font-size:smaller><aside id=authors-holder style="margin:0 0 2%">Cited Authors:
<a href=/cited-authors/Hashimoto-Tatsunori>Hashimoto, Tatsunori</a>
<a href=/cited-authors/Liang-Percy>Liang, Percy</a>
<a href=/cited-authors/R%c3%a9-Christopher>Ré, Christopher</a></aside><aside id=domains-holder style="margin:0 0 2%">Cited Domains:
<a href=/domains/stanford-cs324.github.io style="margin:0 2px"><img src="https://www.google.com/s2/favicons?domain=stanford-cs324.github.io" loading=lazy aria-hidden=true width=16 height=16>
stanford-cs324.github.io</a></aside></div></div><footer><a href=https://www.curiosities.dev/computer-science/large-language-models/llm-evals/>LLM Evals &#187;</a></footer></section></div><footer><a href=mailto:d.chege711@gmail.com>Email</a>
<a href=/about>About</a>
<a href=/search>Search</a></footer></body></html>