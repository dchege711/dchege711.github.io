<!DOCTYPE html>
<html>

    <head>
        <title>
            
                Journal Reviews on Fairness | curiosities.dev
            
        </title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" type="text/css" href="/css/main.css" />
        <link rel="stylesheet" type="text/css" href="/css/all_font_awesome_v5.9.min.css" />
        
        <link rel="shortcut icon" href="/img/favicon_io/favicon.ico">
        <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon_io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon_io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon_io/favicon-16x16.png">

        <link rel="stylesheet" href="/css/vs.css">
        <script type="text/javascript" src="/js/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

        <script type="text/javascript" src="/js/d3/d3.min.js"></script>
        <script type="text/javascript" src="/js/PlotUtils.js"></script>
        <script type="text/javascript" src="/js/OrganizeCitations.js"></script>
        <script type="text/javascript" src="/js/HighlightAnchor.js"></script>

        
        
    </head>

    <body>

        <div class="container" id="main_div">

            
            <form action="/search" method="get" id="globalSearchForm">
                <input type="text" id="q" name="q">
                <input type="submit" id="submitButton" value="Search">
            </form>

            

            <nav aria-label="Breadcrumb" class="breadcrumb">
    <ul>
        







<li>
  <a href="https://www.curiosities.dev/">Home</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/">Computer Science &amp; Software Engineering</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/bias-and-fairness/">Computational Bias and Fairness</a>
</li>


<li class="active">
  <a href="https://www.curiosities.dev/computer-science/bias-and-fairness/2021-10-04-journal-reviews-on-fairness/">Journal Reviews on Fairness</a>
</li>

    </ul>
</nav>



            
<section>
    <header>
    <h1> Journal Reviews on Fairness</h1>
    <p class="meta">
        
        Dated Oct 4, 2021; 
        
        last modified on Fri, 07 Jan 2022
        
    </p>
    </header>

    <div id="toc-then-article">
        <aside id="toc">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#www-21-the-web-conference-2021">WWW &lsquo;21: The Web Conference 2021</a>
      <ul>
        <li><a href="#user-oriented-fairness-in-recommendation-span-classcitation-refa-hrefyunqi2021aspan">User-oriented Fairness in Recommendation <span class="citation-ref"><a href="#Yunqi2021"></a></span></a></li>
        <li><a href="#mitigating-gender-bias-in-captioning-systems-span-classcitation-refa-hreftang2021aspan">Mitigating Gender Bias in Captioning Systems <span class="citation-ref"><a href="#Tang2021"></a></span></a></li>
        <li><a href="#redrawing-district-boundary-to-minimize-spatial-inequality-in-school-funding-span-classcitation-refa-hrefmota2021aspan">Redrawing District Boundary to Minimize Spatial Inequality in School Funding <span class="citation-ref"><a href="#Mota2021"></a></span></a></li>
        <li><a href="#understanding-user-sensemaking-in-machine-learning-fairness-assessment-systems-span-classcitation-refa-hrefgu2021aspan">Understanding User Sensemaking in Machine Learning Fairness Assessment Systems <span class="citation-ref"><a href="#Gu2021"></a></span></a></li>
        <li><a href="#discovering-essential-features-for-preserving-prediction-privacy-span-classcitation-refa-hrefmireshghallah21aspan">Discovering Essential Features for Preserving Prediction Privacy <span class="citation-ref"><a href="#Mireshghallah21"></a></span></a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
        </aside>

        <article id="main-article">
            <h2 id="www-21-the-web-conference-2021">WWW &lsquo;21: The Web Conference 2021</h2>
<h3 id="user-oriented-fairness-in-recommendation-span-classcitation-refa-hrefyunqi2021aspan">User-oriented Fairness in Recommendation <span class="citation-ref"><a href="#Yunqi2021"></a></span></h3>
<p>Showed that active users who only account for a small proportion enjoy much
higher recommendation quality than the majority inactive users. They propose a
re-ranking approach by adding constraints over the evaluation metrics.</p>



<div class="comment-holder">
    <div class="comment open-comment"><p>There&rsquo;s a subtlety here. Although the active users are the minority, the
recommender considers them the majority as they are the ones providing a lot of
the training data.</p>
<p>Maybe recommendations based on collaborative filtering should also divide the
user base into similar cohorts, and learning can take place within these
cohorts? Hold up, doesn&rsquo;t that happen by definition? If I watch movie A and
someone else watched movies A and B, then the recommender can recommend B to me.</p>
<p>It&rsquo;d be helpful to actually read <span class="citation-ref"><a href="#Yunqi2021"></a></span> to see what sort of
constraints were added.</p>
</div>
</div>


<h3 id="mitigating-gender-bias-in-captioning-systems-span-classcitation-refa-hreftang2021aspan">Mitigating Gender Bias in Captioning Systems <span class="citation-ref"><a href="#Tang2021"></a></span></h3>
<p>Captioning datasets, e.g. COCO, contain gender bias found in web corpora.
Authors split the COCO dataset into two where the train and test sets have
different gender-context joint distribution. Models that rely on contextual cues
fail more on the anti-stereotypical test data. Authors propose a model that
provides self-guidance on visual attention to encourage the model to capture
correct gender visual evidence.</p>



<div class="comment-holder">
    <div class="comment open-comment"><p>I don&rsquo;t understand the specifics of this paper from the abstract. What is
&ldquo;visual attention&rdquo; and &ldquo;correct gender visual evidence&rdquo;?</p>
</div>
</div>


<h3 id="redrawing-district-boundary-to-minimize-spatial-inequality-in-school-funding-span-classcitation-refa-hrefmota2021aspan">Redrawing District Boundary to Minimize Spatial Inequality in School Funding <span class="citation-ref"><a href="#Mota2021"></a></span></h3>
<p>Primary source of school district revenue is public money. Authors found that
existing school district boundaries promote financial segregation, with
highly-funded school districts surrounded by lesser-funded districts and
vice-versa. Authors propose the Fair Partitioning problem to divide a set of
schools into \(k\) districts such that the spatial inequality in the
district-level funding is minimized. Authors show that the problem is strongly
-complete, and provide a reasonably effective greedy algorithm.</p>
<h3 id="understanding-user-sensemaking-in-machine-learning-fairness-assessment-systems-span-classcitation-refa-hrefgu2021aspan">Understanding User Sensemaking in Machine Learning Fairness Assessment Systems <span class="citation-ref"><a href="#Gu2021"></a></span></h3>
<p>Considers the tension between de-biasing recommendations which are quick but may
lack nuance, and &lsquo;what-if&rsquo; style exploration which is time-consuming, but may
lead to deeper understanding anf transferable insights. Highlights design
requirements and tradeoffs in the design of ML fairness systems.</p>



<div class="comment-holder">
    <div class="comment"><p>Neat that ML fairness assessment systems exist in the first place!</p>
</div>
</div>


<h3 id="discovering-essential-features-for-preserving-prediction-privacy-span-classcitation-refa-hrefmireshghallah21aspan">Discovering Essential Features for Preserving Prediction Privacy <span class="citation-ref"><a href="#Mireshghallah21"></a></span></h3>
<p>Aims to discern a subset of features necessary for a target prediction task.
Formulates the problem as a gradient-based perturbation maximization method that
discovers the subset with respect to the functionality of the prediction model
used by the provider. The rest of the features are suppressed using
utility-preserving constant values that are discovered through a separate
gradient-based optimization process. The service provider&rsquo;s model can be treated
like a black box. The framework&rsquo;s optimizations reduce the upper bound of the
mutual information between the actual data, and the sifted representations that
get sent out.</p>



<div class="comment-holder">
    <div class="comment"><p>What is &ldquo;perturbation&rdquo; in the context of ML?</p>
<p>Perturbation Theory comprises methods for finding an approximate solution to a
problem, by starting from the exact solution of a related, simpler problem, i.e.
\(A = A_0 + \epsilon^1 A_1 + \epsilon^2 A_2 + &hellip;\), where \(A\) is the full
solution, \(A_0\) is the known solution to the exactly solvable initial
problem, and \(A_1, A_2, &hellip;\) represent the first-order, second-order and
higher-order terms. <span class="citation-ref"><a href="#WikiPerturbation"></a></span></p>
<p>In deep neural network training, perturbation is used to solve various issues,
e.g. perturbing gradients to tackle the vanishing gradient problem; perturbing
weights to escape the saddle point; perturbing inputs to defend against malicious
attacks.
<span class="citation-ref"><a href="#Prakash2020"></a></span></p>
<p><span class="citation-ref"><a href="#WikiAdversarialML"></a></span> features cases of researchers perturbing inputs to
fool ML systems, e.g. perturbing the appearance of a stop sign such that an
autonomous vehicle classified it as a merge or speed limit sign.</p>
</div>
</div>





<div class="comment-holder">
    <div class="comment open-comment"><p>
<a href="https://www.curiosities.dev/computer-science/machine-learning/similarity-based-learning/curse-of-dimensionality-and-feature-selection/"
    
    
    
    >
    The Curse of Dimensionality and Feature Selection
    
</a>
 is a related concept. However, <span class="citation-ref"><a href="#Mireshghallah21"></a></span> seems to
suggest that they can pick a relevant subset of the features without ever
sending them to the server. How can that be?</p>
</div>
</div>


<h2 id="references">References</h2>
<ol>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap'>
    <cite id='Yunqi2021'>
        
        User-Oriented Fairness in Recommendation<i>.</i>
        
    </cite>
    
     Li, Yunqi; Chen, Hanxiong; Fu, Zuohui; Ge, Yingqiang; Zhang, Yongfeng.
     The Web Conference, 2021.
    
    
    
    <a href="https://doi.org/10.1145/3442381.3449866" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
     Apr 19, 2021.
    
     <a href="https://openlibrary.org/search?isbn=9781450383127">ISBN: 9781450383127</a>.
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap'>
    <cite id='Tang2021'>
        
        Mitigating Gender Bias in Captioning Systems<i>.</i>
        
    </cite>
    
     Tang, Ruixiang; Du, Mengnan; Li, Yuening; Liu, Zirui; Zou, Na; Hu, Xia.
     The Web Conference, 2021.
    
    
    
    <a href="https://doi.org/10.1145/3442381.3449950" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
     2021.
     <a href="https://openlibrary.org/search?isbn=9781450383127">ISBN: 9781450383127</a>.
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap'>
    <cite id='Mota2021'>
        
        Fair Partitioning of Public Resources: Redrawing District Boundary to Minimize Spatial Inequality in School Funding<i>.</i>
        
    </cite>
    
     Mota, Nuno; Mohammadi, Negar; Dey, Palash; Gummadi, Krishna P.; Chakraborty, Abhijnan.
     The Web Conference, 2021.
    
    
    
    <a href="https://doi.org/10.1145/3442381.3450041" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
     2021.
     <a href="https://openlibrary.org/search?isbn=9781450383127">ISBN: 9781450383127</a>.
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap'>
    <cite id='Gu2021'>
        
        Understanding User Sensemaking in Machine Learning Fairness Assessment Systems<i>.</i>
        
    </cite>
     Gu, Ziwei; Yan, Jing Nathan; Rzeszotarski, Jeffrey M..
    
     The Web Conference, 2021.
    
    
    
    <a href="https://doi.org/10.1145/3442381.3450092" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
     2021.
     <a href="https://openlibrary.org/search?isbn=9781450383127">ISBN: 9781450383127</a>.
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap'>
    <cite id='Mireshghallah21'>
        
        Not All Features Are Equal: Discovering Essential Features for Preserving Prediction Privacy<i>.</i>
        
    </cite>
    
     Mireshghallah, Fatemehsadat; Taram, Mohammadkazem; Jalali, Ali; Elthakeb, Ahmed Taha Taha; Tullsen, Dean; Esmaeilzadeh, Hadi.
     The Web Conference, 2021.
    
    
    
    <a href="https://doi.org/10.1145/3442381.3449965" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
     2021.
     <a href="https://openlibrary.org/search?isbn=9781450383127">ISBN: 9781450383127</a>.
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe'>
    <cite id='WikiPerturbation'>
        
        Perturbation Theory<i>.</i>
        
    </cite>
    
    
    
    
    
    
    <a href="https://en.wikipedia.org/wiki/Perturbation_theory" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
        <i>en.wikipedia.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe'>
    <cite id='Prakash2020'>
        
        Perturbation Theory in Deep Neural Network (DNN) Training<i>.</i>
        
    </cite>
    
     Prem Prakash.
    
    
    
    
    <a href="https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=towardsdatascience.com" loading="lazy">
        <i>towardsdatascience.com</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
     Mar 20, 2020.
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe'>
    <cite id='WikiAdversarialML'>
        
        Adversarial Machine Learning<i>.</i>
        
    </cite>
    
    
    
    
    
    
    <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
        <i>en.wikipedia.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
</div>

</li>
</ol>

        </article>

        <div style="font-size: smaller;">

<aside id="tags-holder" style="margin: 0 0 2% 0;">
    Tags:
    
        <a href="/tags/ed-tech">#ed-tech</a>
    
        <a href="/tags/gender-bias">#gender-bias</a>
    
        <a href="/tags/privacy">#privacy</a>
    
        <a href="/tags/re-ranking">#re-ranking</a>
    
        <a href="/tags/recommendation-system">#recommendation-system</a>
    
</aside>


<aside id="authors-holder" style="margin: 0 0 2% 0;">
    Cited Authors:
    
        <a href='/authors/chakraborty-abhijnan'>Chakraborty, Abhijnan</a>
    
        <a href='/authors/chen-hanxiong'>Chen, Hanxiong</a>
    
        <a href='/authors/dey-palash'>Dey, Palash</a>
    
        <a href='/authors/du-mengnan'>Du, Mengnan</a>
    
        <a href='/authors/elthakeb-ahmed-taha-taha'>Elthakeb, Ahmed Taha Taha</a>
    
        <a href='/authors/esmaeilzadeh-hadi'>Esmaeilzadeh, Hadi</a>
    
        <a href='/authors/fu-zuohui'>Fu, Zuohui</a>
    
        <a href='/authors/ge-yingqiang'>Ge, Yingqiang</a>
    
        <a href='/authors/gu-ziwei'>Gu, Ziwei</a>
    
        <a href='/authors/gummadi-krishna-p.'>Gummadi, Krishna P.</a>
    
        <a href='/authors/hu-xia'>Hu, Xia</a>
    
        <a href='/authors/jalali-ali'>Jalali, Ali</a>
    
        <a href='/authors/li-yuening'>Li, Yuening</a>
    
        <a href='/authors/li-yunqi'>Li, Yunqi</a>
    
        <a href='/authors/liu-zirui'>Liu, Zirui</a>
    
        <a href='/authors/mireshghallah-fatemehsadat'>Mireshghallah, Fatemehsadat</a>
    
        <a href='/authors/mohammadi-negar'>Mohammadi, Negar</a>
    
        <a href='/authors/mota-nuno'>Mota, Nuno</a>
    
        <a href='/authors/prakash-prem'>Prakash, Prem</a>
    
        <a href='/authors/rzeszotarski-jeffrey-m.'>Rzeszotarski, Jeffrey M.</a>
    
        <a href='/authors/tang-ruixiang'>Tang, Ruixiang</a>
    
        <a href='/authors/taram-mohammadkazem'>Taram, Mohammadkazem</a>
    
        <a href='/authors/tullsen-dean'>Tullsen, Dean</a>
    
        <a href='/authors/yan-jing-nathan'>Yan, Jing Nathan</a>
    
        <a href='/authors/zhang-yongfeng'>Zhang, Yongfeng</a>
    
        <a href='/authors/zou-na'>Zou, Na</a>
    
</aside>



<aside id="publications-holder" style="margin: 0 0 2% 0;">
    Cited Publications:
    
        <a href='/publications/the-web-conference'>The Web Conference</a>
    
</aside>


<aside id="domains-holder" style="margin: 0 0 2% 0;">
    Cited Domains:
    
        <a href='/domains/doi.org' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
            doi.org
        </a>
    
        <a href='/domains/en.wikipedia.org' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
            en.wikipedia.org
        </a>
    
        <a href='/domains/towardsdatascience.com' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=towardsdatascience.com" loading="lazy">
            towardsdatascience.com
        </a>
    
</aside>

</div>

    </div>
    <footer>
        
        
        
            
        

        
            <a href="https://www.curiosities.dev/computer-science/bias-and-fairness/2021-03-03-on-the-dangers-of-stochastic-parrots/">&laquo; On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜</a>
        
        

    </footer>
</section>


        </div>

        <footer>
            <a href="mailto:d.chege711@gmail.com">Email</a>
            
            <a href="/about">About</a>
            <a href="/search">Search</a>
        </footer>

    </body>

</html>
