<!doctype html><html lang=en><head><title>Computational Bias and Fairness | curiosities.dev</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet type=text/css href=/css/main.min.css><link rel=preload href=/css/all_font_awesome_v5.9.min.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=/css/all_font_awesome_v5.9.min.min.css></noscript><link rel="shortcut icon" href=/img/favicon_io/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/img/favicon_io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon_io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon_io/favicon-16x16.png><link rel=preload href=/css/vs.min.css as=style onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel=stylesheet href=/css/vs.min.css></noscript><script defer type=text/javascript src=/js/highlight.min.min.js></script><script defer>const hjlsURLRegex=/https?:\/\/[^\s<]+/g
const hjlsCitationRegex=/&lt;span class=&quot;citation-ref&quot;&gt;&lt;a href=&quot;(.*)&quot;&gt;&lt;\/a&gt;&lt;\/span&gt;/g
hljs.addPlugin({"after:highlight":(result)=>{result.value=result.value.replaceAll(hjlsURLRegex,"<a href='$&' target='_blank'>$&</a>");console.log(result.value);result.value=result.value.replaceAll(hjlsCitationRegex,"<span class='citation-ref'><a href='$1'></a></span>");}});hljs.highlightAll();</script><script async type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script async type=text/javascript src=/js/d3/d3.min.min.js></script><script async type=text/javascript src=/js/PlotUtils.min.js></script><script async type=text/javascript src=/js/OrganizeCitations.min.js></script><script async type=text/javascript src=/js/HighlightAnchor.min.js></script><script async type=text/javascript src=/js/SummaryPageUtils.min.js></script><script async type=text/javascript src=/js/AnimateBackground.min.js></script></head><svg id="background-svg"/><body><div class=container id=main_div><form action=/search method=get id=globalSearchForm><input type=text id=q name=q title="Search Query">
<input type=submit id=submitButton value=Search></form><nav aria-label=Breadcrumb class=breadcrumb><ul><li><a href=https://www.curiosities.dev/>Home</a></li><li><a href=https://www.curiosities.dev/computer-science/>Computer Science & Software Engineering</a></li><li class=active><a href=https://www.curiosities.dev/computer-science/bias-and-fairness/>Computational Bias and Fairness</a></li></ul></nav><main><article><header><h1>Computational Bias and Fairness</h1><p class=meta>Dated Oct 4, 2021;
last modified on Sun, 23 Jan 2022</p></header><div class=comment-holder><div class="comment open-comment"><p>Check out
<a href=https://klasses.cs.uchicago.edu/archive/2020/winter/20370-1/index.html target=_blank rel=noopener>CMSC 20370/30370: Inclusive Technology: Design For Underserved and
Marginalized
Communities
<i class="fas fa-fw fa-external-link-alt" aria-hidden=true></i></a>,
and other similar courses.</p></div></div></article><table border=0><tr class=no-decoration id=randomSelectorContainer><td class=no-decoration></td><td class=no-decoration></td><td class=no-decoration><span class=link-style onclick=goToRandomPage();>Random Link Â¯\_(ãƒ„)_/Â¯</span></td></tr><tr class=no-decoration><td class=no-decoration>Mar 3, 2021</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/computer-science/bias-and-fairness/2021-03-03-on-the-dangers-of-stochastic-parrots/>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ</a>
<span class=meta>3 min; updated Sep 5, 2022
<button id=64c2e4d7329a2151b34c2735b3a09fdf-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=64c2e4d7329a2151b34c2735b3a09fdf-summary style=display:none>The paper is written in a period when NLP practitioners are producing bigger (# of parameters; size of training data) language models (LMs), and pushing the top scores on benchmarks.
Environmental Risks Large LMs consume a lot of resources, e.g. training a single BERT base model on GPUs was estimated to use as much energy as a trans-American flight.
Marginalized communities are doubly punished. They are least likely to benefit from LMs, e....</p></td></tr><tr class=no-decoration><td class=no-decoration>Jul 4, 2021</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/computer-science/bias-and-fairness/2021-07-04-rage-against-the-algo/>Rage Against the Algorithm</a>
<span class=meta>4 min; updated Sep 5, 2022
<button id=5ffba38e7b7ae7bc4da5ab40a3a529f4-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=5ffba38e7b7ae7bc4da5ab40a3a529f4-summary style=display:none>The lack of explanability is a common theme. Higher-ups claim the machine is unbiased, while the workers on the ground say, &ldquo;It&rsquo;s not me; it&rsquo;s the computer&rdquo;.
Automating Inequality: How High-tech Tools Profile, Police, and Punish the Poor should be an enlightening read.
Computers Can Solve Your Problem. You May Not Like the Answer The algorithm had four guiding principles:
Increase # of high school students starting after 8am Decrease # of elementary school students dismissed after 4pm Accommodate the needs of special education students Generate transportation savings Unprecedented opposition to the algorithm&rsquo;s solution....</p></td></tr><tr class=no-decoration><td class=no-decoration>Oct 4, 2021</td><td class=no-decoration>&#187;</td><td class=no-decoration><a href=https://www.curiosities.dev/computer-science/bias-and-fairness/2021-10-04-journal-reviews-on-fairness/>Journal Reviews on Fairness</a>
<span class=meta>7 min; updated Sep 5, 2022
<button id=67b0f05b387e6aac6e1c181ea67058e0-summary-controller onclick=toggleSummaryDisplay(this);>
<i class="fas fa-chevron-down"></i></button></span><p class=meta id=67b0f05b387e6aac6e1c181ea67058e0-summary style=display:none>Meta ðŸ“‘ Instead of changing the data or learners in multiple ways and then see if fairness improves, postulate that the root causes of bias are the prior decisions that generated the training data. These affect (a) what data was selected, and (b) the labels assigned to the examples. They propose the \(\text{Fair-SMOTE}\) (Fair Synthetic Minority Over Sampling Technique) algorithm which (1) removes biased labels (via situation testing: if the model&rsquo;s prediction for a data point changes once all of the data points' protected attributes are flipped, then that label is biased and the data point is discarded), and (2) rebalances internal distributions such that based on a protected attribute, examples are equal in both positive and negative classes....</p></td></tr></table><script>let pageURLs=[];const alternateOrganizations=new Set(["tags","categories","domains","authors","publications"]);fetch("/json/site_tree.json").then(response=>response.json()).then(siteTree=>{const currentPath=document.location.pathname;let node=siteTree;currentPath.split("/").forEach((subpath)=>{if(!subpath)return;node=node[subpath];});if(!node)return;function populateRelevantURLs(partialURL,currentNode){const currentNodeKeys=Object.keys(currentNode);currentNodeKeys.forEach((key)=>{if(key==="_meta")return;if(currentPath==="/"&&alternateOrganizations.has(key))
return;let nextPartialURL=partialURL===""?key:`${partialURL}/${key}`;populateRelevantURLs(nextPartialURL,currentNode[key]);});if(currentNodeKeys.length===0&&partialURL){pageURLs.push(partialURL);}}
populateRelevantURLs("",node);}).then(()=>{if(pageURLs.length===0){document.getElementById("randomSelectorContainer").style.display="none";}});function goToRandomPage(){let idx=Math.floor(Math.random()*(pageURLs.length));window.open(pageURLs[idx],"_self");}</script></main></div><footer><a href=mailto:d.chege711@gmail.com>Email</a>
<a href=/about>About</a>
<a href=/search>Search</a></footer></body></html>