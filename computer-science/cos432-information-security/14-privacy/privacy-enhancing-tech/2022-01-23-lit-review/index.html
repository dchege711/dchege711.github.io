<!DOCTYPE html>
<html>

    <head>
        <title>
            
                Research on Privacy Enhancing Techniques | curiosities.dev
            
        </title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" type="text/css" href="/css/main.css" />
        <link rel="stylesheet" type="text/css" href="/css/all_font_awesome_v5.9.min.css" />
        
        <link rel="shortcut icon" href="/img/favicon_io/favicon.ico">
        <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon_io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon_io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon_io/favicon-16x16.png">

        <link rel="stylesheet" href="/css/vs.css">
        <script type="text/javascript" src="/js/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

        <script type="text/javascript" src="/js/d3/d3.min.js"></script>
        <script type="text/javascript" src="/js/PlotUtils.js"></script>
        <script type="text/javascript" src="/js/OrganizeCitations.js"></script>
        <script type="text/javascript" src="/js/HighlightAnchor.js"></script>

        
        
    </head>

    <body>

        <div class="container" id="main_div">

            
            <form action="/search" method="get" id="globalSearchForm">
                <input type="text" id="q" name="q">
                <input type="submit" id="submitButton" value="Search">
            </form>

            

            <nav aria-label="Breadcrumb" class="breadcrumb">
    <ul>
        











<li>
  <a href="https://www.curiosities.dev/">Home</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/">Computer Science &amp; Software Engineering</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/cos432-information-security/">Information Security [COS 432]</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/">14. Privacy</a>
</li>


<li>
  <a href="https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/privacy-enhancing-tech/">Privacy Enhancing Techniques</a>
</li>


<li class="active">
  <a href="https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/privacy-enhancing-tech/2022-01-23-lit-review/">Research on Privacy Enhancing Techniques</a>
</li>

    </ul>
</nav>



            
<section>
    <header>
    <h1> Research on Privacy Enhancing Techniques</h1>
    <p class="meta">
        
        Dated Jan 23, 2021; 
        
        last modified on Sun, 23 Jan 2022
        
    </p>
    </header>

    <div id="toc-then-article">
        <aside id="toc">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#journals">Journals</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
        </aside>

        <article id="main-article">
            <h2 id="journals">Journals</h2>
<p><span class="citation-ref"><a href="#Mireshghallah2021"></a></span> note that prediction services can still make
accurate predictions using a fraction of the data collected from a user device.
They propose Cloak, which suppresses non-pertinent features (i.e. those features
which can consistently tolerate addition of noise without degrading utility) to
the prediction task. Cloak has a provable degree of privacy, and unlike
cryptographic techniques, does not degrade prediction latency. Using the
training data, labels, a pre-trained model and a privacy-utility knob, they (1)
find the pertinent features through perturbation training, and (2) learn
utility-preserving constant values for suppressing the non-pertinent data.
During the inference phase, they efficiently compute a sifted representation
which is sent to the service provider.</p>
<figure>
    <img src="/img/computer-science/cos432-information-security/14-privacy/cloaks-sifted-representation.jpg"
         alt="From Mireshghallah2021: Cloak&amp;rsquo;s discovered features for target DNN
classifiers for black hair color, eyeglasses, gender and smile detection. SR =
suppression ratio. AL denotes the range of accuracy loss imposed by the
suppression."/> <figcaption>
            <p>From Mireshghallah2021: Cloak&rsquo;s discovered features for target DNN
classifiers for black hair color, eyeglasses, gender and smile detection. SR =
suppression ratio. AL denotes the range of accuracy loss imposed by the
suppression.</p>
        </figcaption>
</figure>




<div class="comment-holder">
    <div class="comment"><p>Perturbation Theory comprises methods for finding an approximate solution to a
problem, by starting from the exact solution of a related, simpler problem, i.e.
\(A = A_0 + \epsilon^1 A_1 + \epsilon^2 A_2 + &hellip;\), where \(A\) is the full
solution, \(A_0\) is the known solution to the exactly solvable initial
problem, and \(A_1, A_2, &hellip;\) represent the first-order, second-order and
higher-order terms. <span class="citation-ref"><a href="#WikiPerturbation"></a></span></p>
<p>In deep neural network training, perturbation is used to solve various issues,
e.g. perturbing gradients to tackle the vanishing gradient problem; perturbing
weights to escape the saddle point; perturbing inputs to defend against
malicious attacks. <span class="citation-ref"><a href="#Prakash2020"></a></span></p>
<p><span class="citation-ref"><a href="#WikiAdversarialML"></a></span> features cases of researchers perturbing inputs
to fool ML systems, e.g. perturbing the appearance of a stop sign such that an
autonomous vehicle classified it as a merge or speed limit sign.</p>
</div>
</div>





<div class="comment-holder">
    <div class="comment"><p><span class="citation-ref"><a href="#Mireshghallah2021"></a></span> go through the trouble of learning
utility-preserving constants because (1) simply adding noise could still leak
data and/or push the values out of the domain of the classifier, and (2)
zero-ing out the non-pertinent might degrade accuracy because the zeros might
not match the distribution of the data that the classifier expects.</p>
</div>
</div>


<h2 id="references">References</h2>
<ol>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-graduation-cap' cited-by-count=''>
    <cite id='Mireshghallah2021'>
        
        Not All Features Are Equal: Discovering Essential Features for Preserving Prediction Privacy<i>.</i>
        
    </cite>
     Mireshghallah, Fatemehsadat; Taram, Mohammadkazem; Jalali, Ali; Elthakeb, Ahmed Taha Taha; Tullsen, Dean; Esmaeilzadeh, Hadi.
    
     The Web Conference, 2021.
    
     University of California, San Diego; Amazon; Samsung Electronics.
    
    <a href="https://doi.org/10.1145/3442381.3449965" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
        <i>doi.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C48&amp;q=author%3AMireshghallah&#43;Not&#43;All&#43;Features&#43;Are&#43;Equal%3A&#43;Discovering&#43;Essential&#43;Features&#43;for&#43;Preserving&#43;Prediction&#43;Privacy&amp;btnG=" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=scholar.google.com" loading="lazy">
        <i>scholar.google.com</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
     2021.
    
    
    <i class='fas fa-fw fa-graduation-cap' aria-hidden="true"></i>
    
    
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe' cited-by-count=''>
    <cite id='WikiPerturbation'>
        
        Perturbation Theory<i>.</i>
        
    </cite>
    
    
    
    
    
    
    <a href="https://en.wikipedia.org/wiki/Perturbation_theory" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
        <i>en.wikipedia.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe' cited-by-count=''>
    <cite id='Prakash2020'>
        
        Perturbation Theory in Deep Neural Network (DNN) Training<i>.</i>
        
    </cite>
    
     Prem Prakash.
    
    
    
    
    <a href="https://towardsdatascience.com/perturbation-theory-in-deep-neural-network-dnn-training-adb4c20cab1b" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=towardsdatascience.com" loading="lazy">
        <i>towardsdatascience.com</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
     Mar 20, 2020.
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
    
</div>

</li>
<li>

    

<div class="citation" citation-icon-class='fas fa-fw fa-globe' cited-by-count=''>
    <cite id='WikiAdversarialML'>
        
        Adversarial Machine Learning<i>.</i>
        
    </cite>
    
    
    
    
    
    
    <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning" target="_blank" rel="noopener">
        <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
        <i>en.wikipedia.org</i> <i class="fas fa-fw fa-external-link-alt" aria-hidden="true"></i>
    </a>.
    
    
    
    
    
    
    
    <i class='fas fa-fw fa-globe' aria-hidden="true"></i>
    
     Accessed Oct 11, 2021.
    
</div>

</li>
</ol>

        </article>

        <div style="font-size: smaller;">


<aside id="authors-holder" style="margin: 0 0 2% 0;">
    Cited Authors:
    
        <a href='/authors/elthakeb-ahmed-taha-taha'>Elthakeb, Ahmed Taha Taha</a>
    
        <a href='/authors/esmaeilzadeh-hadi'>Esmaeilzadeh, Hadi</a>
    
        <a href='/authors/jalali-ali'>Jalali, Ali</a>
    
        <a href='/authors/mireshghallah-fatemehsadat'>Mireshghallah, Fatemehsadat</a>
    
        <a href='/authors/prakash-prem'>Prakash, Prem</a>
    
        <a href='/authors/taram-mohammadkazem'>Taram, Mohammadkazem</a>
    
        <a href='/authors/tullsen-dean'>Tullsen, Dean</a>
    
</aside>



<aside id="publications-holder" style="margin: 0 0 2% 0;">
    Cited Publications:
    
        <a href='/publications/the-web-conference'>The Web Conference</a>
    
</aside>


<aside id="affiliations-holder" style="margin: 0 0 2% 0;">
    Cited Authors' Affiliations:
    
        <a href='/affiliations/amazon'>Amazon</a>
    
        <a href='/affiliations/samsung-electronics'>Samsung Electronics</a>
    
        <a href='/affiliations/university-of-california-san-diego'>University of California, San Diego</a>
    
</aside>


<aside id="domains-holder" style="margin: 0 0 2% 0;">
    Cited Domains:
    
        <a href='/domains/doi.org' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=doi.org" loading="lazy">
            doi.org
        </a>
    
        <a href='/domains/en.wikipedia.org' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=en.wikipedia.org" loading="lazy">
            en.wikipedia.org
        </a>
    
        <a href='/domains/scholar.google.com' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=scholar.google.com" loading="lazy">
            scholar.google.com
        </a>
    
        <a href='/domains/towardsdatascience.com' style="margin: 0px 2px;">
            <img src="https://www.google.com/s2/favicons?domain=towardsdatascience.com" loading="lazy">
            towardsdatascience.com
        </a>
    
</aside>

</div>

    </div>
    <footer>
        
        
        
            
        

        
            <a href="https://www.curiosities.dev/computer-science/cos432-information-security/14-privacy/privacy-enhancing-tech/secure-multiparty-computation/">&laquo; Secure Multiparty Computation</a>
        
        

    </footer>
</section>


        </div>

        <footer>
            <a href="mailto:d.chege711@gmail.com">Email</a>
            
            <a href="/about">About</a>
            <a href="/search">Search</a>
        </footer>

    </body>

</html>
